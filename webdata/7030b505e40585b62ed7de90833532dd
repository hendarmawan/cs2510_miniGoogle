<HTML>
<BODY bgcolor=white>
<p>
<!--. EQ -->
<PRE>
<!--
delim gsize 9
define &lt;0 ' size 7  sub size 4 {0} '
define &lt;1 ' size 7  sub size 4 {1} '
define &lt;2 ' size 7  '
define &lt;i ' size 7  sub size 4 {i} '
define &gt;0 ' size 7  sub size 4 {0} '
define &gt;1 ' size 7  sub size 4 {1} '
define &gt;2 ' size 7  '
define &gt;i ' size 7  sub size 4 {i} '
define _0 ' size 7  sub size 4 {0} '
define _1 ' size 7  sub size 4 {1} '
define _2 ' size 7  '
define _i ' size 7  sub size 4 {i} '
define u0 ' size 7  sub size 4 {0} '
define u1 ' size 7  sub size 4 {1} '
define u2 ' size 7  '
define ui ' size 7  sub size 6 {i} '
-->
<!--. EN -->
</PRE>
<!--. nr LL 6.85i-->
<!--. nr PS 10-->
<!--. nr VS 11-->
<!--. ls 1-->
<!--. TL -->
<TITLE>A Methodology and Interactive Environment fo Iconic Language Design</TITLE>
<!-- Changed by: unknown, 22-Mar-1997 -->
</HEAD>
<BODY bgcolor=white>
<H1>
<!--. ps 13-->
<center>
A Methodology and Interactive Environment for Iconic Language Design
<!--. AU -->
</H1>
<BR>
<!--. ps 10-->
<i>S. K. Chang, G. Polese</i>
<!--. AI -->
<BR>
<p>
<!--. ps 10-->
Department of Computer Science<br>
University of Pittsburgh<br>
Pittsburgh, PA 15260<br>
<p>
<!--. AU -->
<BR>
<br><br>
<!--. ps 10-->
<i>S. Orefice, M. Tucci</i><br>
<p>
<!--. AI -->
<!--. ps 10-->
Dipartimento di Informatica ed Applicazioni<br>
Universita' degli Studi di Salerno<br>
Baronissi (SA), Italy<br>
<!--. LP -->
<P>
<br><br><br>
<!--. ls 1-->
<!--. ce -->
ABSTRACT
</center>
<!--. LP -->
</P>
<P>
<i>We describe a design methodology for iconic languages
based upon the theory of icon algebra to derive the meaning of iconic sentences.
The design methodology serves two purposes.
First of all, it is a descriptive model for the design process of the
iconic languages used in the Minspeak<sup>TM</sup> systems for augmentative communication.Second, it is also a prescriptive model for the design of 
other iconic languages for human-machine interface.
An interactive design environment based upon this methodology is described.
This investigation raises a number of interesting issues regarding
iconic languages and iconic communications.
</i>
<p>
<p>
<!--. ls 2-->
<!--. NH 1-->
</P>
<H2>
1.
Introduction
<!--. PP -->
</H2>
<P>
Iconic languages are visual languages where each visual sentence is
a spatial arrangement of icons.
An essential feature of the iconic languages is that such languages are
based upon a vocabulary of icons where each icon has unique or multiple meanings.
These languages have been used successfully in human-computer interface,
visual programming, and human-human communication.  The iconic language used in human-computer communication usually has a limited
vocabulary of icons and a specific application domain: database access, form
manipulation, image processing, etc.
There are also iconic languages for human-human communication
used in </2><I>augmentative communication</I>
by people with speech disabilities.
Finally, there are &quot;natural&quot; iconic languages such as the Chinese ideographs,
the Mayan glyphs and the Egyptian pictograms.
<!--. PP -->
</P>
<P>
In this paper we present a design methodology for iconic languages.
The design methodology serves two purposes.
First of all, it is a descriptive model for the design process of the
iconic languages used in the Minspeak<sup>TM</sup> systems for augmentative communication.Second, it is also a prescriptive model for the design of 
other iconic languages for human-machine interface.
We hope the experience learned from the case study of iconic language design for
the Minspeak<sup>TM</sup> systems will lead to some valuable insightin the design of iconic languages in general.
We do not claim that iconic languages are adequate or even appropriate for all
purposes.   However, if there is a need for designing an iconic language,
the design methodology presented in this paper can be useful.
<!--. PP -->
</P>
<P>
There are a variety of augmentative communication systems for people with 
physical limitations or speech impediments, ranging from unaided communication 
such as American Sign Language, to aided communication systems such as 
computerized voice output systems.  The Minspeak<sup>TM</sup> systems conceived by Bruce Baker use the principle of <I>semantic compaction</I>
<!--. [[ -->
Baker Barry
<!--. ] -->
<!--. [ -->
Disabled Individuals
<!--. ] -->
<!--. [ -->
Bray
<!--. ] -->
<!--. [ -->
Baker Nyberg
<!--. ]] .-->
It involves mapping concepts on to multimeaning
icon sentences and using these icon sentences to retrieve
messages stored in the memory of a microcomputer.
The stored messages can be words or word sequences.
A built-in speech synthesizer can then be used to generate the
voice output.
Over the past ten years, more than 20,000 Minspeak<sup>TM</sup> units have been distributed all over the world.  Swedish, German, Italian and other Minspeak 
<sup>TM</sup> systems are being developed.
<!--. PP -->
</P>
<P>
The Minspeak<sup>TM</sup> Iconic keyboard is shown in Figure 1.When the user touches the icons on the keyboard, the system produces the voice 
output. Thus the Minspeak<sup>TM</sup> keyboard can serve as an augmentative communication system.  For example, when the APPLE icon and the VERB icon are 
depressed in that order, the system produces the voice output &quot;eat&quot;.  The 
sequence &quot;APPLE VERB&quot; is called an <I>iconic sentence</I>.  A different iconic 
sentence such as &quot;APPLE NOUN&quot; will produce the voice output &quot;food&quot;.  The APPLE 
icon by itself is thus ambiguous.
The basic idea of <I>semantic compaction</I> is to use ambiguous icons to
represent concepts.  For example, the APPLE icon can represent &quot;eat&quot; or &quot;food&quot;. 
Ambiguity is resolved, when several icons are combined into an iconic 
sentence.  This principle allows the representation of many concepts (usually 
around two thousand) using a few icons (usually around fifty).  It is important
to note that the user can enter a concept with just a few keystrokes, instead of entering every letter of the word.
The design of the Minspeak<sup>TM</sup> systems therefore involves the encodingof concepts into iconic sentences.
<!--. PP -->
</P>
<P>
Our approach is to formalize the methodology to
design iconic languages based upon the theory of <I>Icon Algebra</I> to derive the meaning of iconic sentences.
The formalization of the design methodology will lead
to a deeper understanding of iconic languages and iconic communications,
so that certain theoretical issues can be further explored in this
framework.
<!--. PP -->
</P>
<P>
The paper is organized as follows.
Section 2 introduces the theory of <I>Icon Algebra</I>
<!--. [[ -->
Chang Icon Semantics - A Formal Approach
<!--. ] -->
<!--. [ -->
Chang Principles of Pictorial Information Systems
<!--. ]] -->
as a formal approach for deriving the meaning of iconic sentences.
Section 3 outlines the design methodology for iconic languages
including in particular the
Minspeak<sup>TM</sup> systems.  Based upon this design methodology,an interactive design environment, which has been implemented on IBM PC, is presented in Section 4.
Since knowledge representation is critical to the success of
the design methodology, we explain in Section 5 how the frame-based
representation can be augmented by the theory of <I>Conceptual Dependency</I>
to serve as the semantic model of iconic sentences.
The algorithm for making inferences using the icon algebra and the augmented frame representation
is presented in Section 6.
In the design process, a critical issue is the construction of
the conceptual similarity function, which is presented in Section 7.
Section 8 describes the design methodology in detail and also gives a detailed example based upon the Minspeak<sup>TM</sup>systems.  In Section 9, we discuss a number of interesting issues for further exploration.
<!--. NH 1-->
</P>
<H2>
2.
The Icon Algebra for Deriving Icon Semantics
<!--. PP -->
</H2>
<P>
<!--. PP -->
</P>
<P>
As a formal model to describe the semantic combination of icons we have exploited
the theory of <I>Icon Algebra</I>
<!--. [[ -->
Chang Icon Semantics - A Formal Approach
<!--. ] -->
<!--. [ -->
Chang Principles of Pictorial Information Systems
<!--. ]] .-->
Icon algebra provides a powerful way to derive new meanings of an icon, or an 
iconic sentence, by applying some formal operators on it. An icon X is seen as 
a pair (X<sub>m</sub>,X<sub>i</sub>) where  X<sub>m</sub> represents the meaning of the icon, or the logical part, and X<sub>i</sub> represents the image, or the physical part. An essential characteristic of an icon is that the logical part and the 
physical part are mutually dependent. That is, if the image is changed, its 
meaning will also be changed and vice versa. 
When more than one icon is employed to derive the 
new meaning, all the involved icons together will constitute the iconic 
sentence to encode the newly derived concept.
<!--. nr -->
Furthermore, an icon image contains both global and local features. A global 
feature of an icon represents the primary concept expressed by the image, 
whereas a local feature represents a secondary concept. Therefore, the meaning 
part X<sub>m</sub> of an icon X is in general a conceptual structure.<!--. PP -->
</P>
<P>
As mentioned above, the icon algebra applies some formal operators to icons to 
derive new icons. The icon operators are defined below, where X and Y are the 
operand icons and Z is the resultant composite icon.  In what follows, X.[u]A 
means X has an attribute u whose value is A.  If A has again an attribute v 
whose value is B, we write X.[u]A.[v]B.  The primary meaning P of the icon X is
usually denoted by X.[is]P, although any X.[u]P could be made to be the primary
meaning of X. We often use the primary meaning P to refer to the conceptual 
structure X<sub>m</sub>, and write X = (P, X<sub>i</sub>).The six icon operators - combination COM, marking MAR, contextual interpretation CON,
enhancement ENH, inversion INV and indexing IDX - will now be explained.
<!--. nf -->
<BR>
<p>
1. Combination COM:	 COM (X,Y)
<BR>
<p>
(Figure of COM operator in minsfig/com.ps)
<BR>
<!--. fi -->
<BR>
<p>
The COM operator performs the <I>conceptual merge</I> of the meanings associated with the individual 
icons X and Y. In the example above, the combination of &quot;jump&quot; and &quot;volt&quot; 
yields &quot;hurry&quot; because they both have the secondary meaning 
&quot;hurry&quot; among their possible 
meanings, although this is not the primary meaning in either of them.  Therefore only
their combination leads to the concept &quot;hurry&quot;.
Formally, X.[is]jump.[recall]fast combined with Y.[is]volt.[quality]fast
results in Z.[is]hurry.
(In the above, &quot;jump&quot; leads one to recall the concept &quot;fast&quot;,
&quot;volt&quot; has the quality &quot;fast&quot;, and the resultant composite icon has the primary meaning &quot;hurry&quot;.)
The conceptual merge is possible only when &quot;jump&quot; and &quot;volt&quot; or their derived 
attributes are in the conceptual structure of &quot;hurry&quot;.
In other words, the two concepts are somehow related within the conceptual 
structure of the resultant concept.
<p>
2. Marking MAR:	 MAR (X,Y)
<p>
The marking operator marks the image of the icon Y with the image of 
the icon X to emphasize a local feature. Here the first icon plays 
the role of &quot;marker image&quot;. For example:
<p>
(Figure of MAR operator in minsfig/mar.ps)
<p>
Inside the &quot;chest&quot; there is &quot;treasure&quot;, and the &quot;color&quot; of &quot;treasure&quot; 
is &quot;gold&quot;.  Since &quot;rainbow&quot; means &quot;color&quot;, the marking of
&quot;chest&quot; by &quot;color&quot; results in &quot;gold&quot;.  Formally,
Y.[is]chest.[quality]treasure.[color]gold marked by
X.[is]rainbow.[recall]color
results in Z.[is]gold.  Using the Chinese character as another example,
Y.[is]tree.[part]root.[location]low marked by
X.[is]low_marker.[recall]low results in Z.[is]root.
Thus marking is a <I>conceptual restriction</I> to extract an important local feature.
<p>
<!--. nf -->
<BR>
3. Contextual Interpretation CON:	 CON (X,Y)
<BR>
<!--. fi -->
<BR>
<p>
The meaning of the icon X is considered in the context of Y,
and the result usually is a <I>conceptual refinement</I> (specialization) of the meaning of X.
For example:
<!--. nf -->
<BR>
<p>
(Figure of CON operator in minsfig/con.ps)
<BR>
<!--. fi -->
<BR>
<p>
Since &quot;apple&quot; recalls the concept of &quot;food&quot;, &quot;food&quot; in the &quot;morning&quot; 
leads to &quot;breakfast&quot;. Therefore
X.[is]apple.[is_a_concrete]food in the context of Y.[time]morning
results in Z.[is]breakfast, and
&quot;breakfast&quot; is a subclass of &quot;food&quot; in the hierarchy.
<!--. nf -->
<BR>
<p>
4. Enhancement ENH:	 ENH (X,Y)
<BR>
<p>
<!--. fi -->
<BR>
This operator enhances the conceptual richness of the icon X by 
adding attributes from Y, and
the result usually is an enrichment of the meaning of X.
For example:
<!--. nf -->
<BR>
<p>
(Figure of ENH operator in minsfig/enh.ps)
<BR>
<p>
<!--. fi -->
<BR>
<p>
Since &quot;low temperature&quot; corresponds to &quot;cold&quot;, 
X.[is]thermometer.[use]temperature enhanced by Y.[is]thumb_down.[recall]low
leads to Z.[is]cold.
Enhancement is similar to combination, in that the two concepts
must be somehow related.  However, for the combination operator,
the two icons contribute equally and are both indispensable.  For the 
enhancement operator,
the first icon plays the more important role, and the second icon is usually a modifier.
For example, the second icon can be replaced
by Y.[is]low_marker.[recall]low, and the result would be the same.
<p>
5. Inversion INV:	 INV (X)
<p>
The meaning of the icon X is inverted. 
The inversion operator has only one argument.
For example:
<!--. nf -->
<BR>
<p>
(Figure of INV operator in minsfig/inv.ps)
<BR>
<p>
<!--. fi -->
<BR>
God stands for &quot;true&quot;, so the negation of &quot;true&quot; is &quot;false&quot;. In the Minspeak<sup>TM</sup> iconic language, the icon&quot;knot&quot; stands for negation because it is homonymous to &quot;not&quot;.
Thus X.[is]god.[recall]true with the negation operator 
Y.[is]knot.[rhyme]not leads to Z.[is]false.
<p>
6. Indexing IDX:	 IDX (X)
<p>
The index operator extracts the important meaning of an icon that will serve as an 
index to the original icon. For example:
<!--. nf -->
<BR>
<p>
(Figure of IDX operator in minsfig/idx.ps)
<BR>
<p>
<!--. fi -->
<BR>
The icon X may have multiple attributes, but one
important attribute is &quot;big&quot;, which is extracted to become the primary meaning of the new icon Y.  Later on we will use a fuzzy semantic parameter to express 
the importance of an attribute.
<!--. PP -->
</P>
<P>
In addition to the six iconic operators described above, there
are other operators
<!--. [ -->
Chang Principles of Pictorial Information Systems Design
<!--. ] -->
so that both the meaning and the image of the composite icon
can be modified.
<!--. NH 1-->
</P>
<H2>
3.
A Design Methodology for Iconic Languages
<!--. PP -->
</H2>
<P>
The objective of the design methodology can be stated as follows. Let K be aset of words (for example part of the vocabulary of a natural language, as in the case  
of the Minspeak, or the set of feasible commands and entities in some application domain),
the objective is to design an iconic language for K, i.e., a set of icons I such thateach word in K is encoded by an iconic sentence with at most <I>max</I> icons from I, where <I>max</I> is a predefined parameter.The encoding should be accomplished such that 
each word in the application domain is associated with a visual sentence that
evokes the meaning of the word.
<!--. PP -->
</P>
<P>
The design methodology consists of three major steps.
In what follows, we will give a brief description of the design process, which will be 
treated in more detail in Section 8.
<!--. PP -->
</P>
<P>
The first step is to find the basic words in K, i.e., those very important words whichshould be represented directly by icon images. This subset of basic words, K<sub>B</sub>,can be obtained by opportunely partitioning K and then picking upthe most relevant words from each set of the partition according to the following criterion
of relevancy. The <I>relevancy</I> of a concept is a composite measure, including the frequency
of usage of the concept, the intrinsic importance of the concept, and how
the concept is likely to cover the meaning of other concepts. The formula we use to compute
the relevancy r<sub>j</sub> of a word k<sub>j</sub> is as follows:<!--. PP -->
</P>
<P>
r<sub>j</sub> = 1                           if p &gt;= t<!--. PP -->
</P>
<P>
r<sub>j</sub> = w<sub>1</sub> f +w<sub>2</sub> i + w<sub>3</sub> p       otherwise<!--. nf -->
<BR>
<!--. na -->
where:
<BR>
<!--. in 2-->
f is the frequency of the word, f in [0,1],<BR>
i is the intrinsic importance of the word, i in [0,1],<BR>
p indicates how likely will the word cover the meaning<BR>
  of other words, p in [0,1],<BR>
t is a fixed threshold in [0,1], normally close to 1,<BR>
<!--. fi -->
<!--. ad -->
w<sub>k</sub> are weights indicating the contribution of the corresponding feature to the relevancy in the domain specification, w<sub>k</sub> &gt;=0 and w<sub>1</sub>+w<sub>2</sub>+w<sub>3</sub>=1. <!--. in 0-->
<p>
<!--. PP -->
</P>
<P>
The second step is to invent an icon image for each basic word in 
K<sub>B</sub>. The image of the icon associated with a basic word should immediatelyevoke the meaning of the word. Moreover, the graphics can be enriched in order to
cover other possible meanings. These icons are included in the set of basic icons I. In addition, I can be augmented by a few more icons depending on the application domain. Forexample, in the Minspeak<sup>TM</sup> iconic language I also contains some icons representing the syntacticcategories C = {noun, adjective, verb, ...}.
<!--. PP -->
</P>
<P>
Finally, in the third step the encoding
of words into iconic sentences is accomplished.  For each word k<sub>i</sub> to encode,the designer must choose one iconic sentence from a set of candidate sentences
with similar meanings to encode the word.
If a failure in the
encoding process occurs, the designer first attempts to redesign the icons without changing
K<sub>B</sub>, because maybe the icon images are not appropriate.  If anencoding still cannot be found, the designer then modifies K<sub>B</sub>.<!--. PP -->
</P>
<P>
The above design approach requires 
a knowledge representation to describe the semantics of words, icons and iconic sentences,
and a conceptual similarity function to
measure the similarity between words (or concepts),
icons and iconic sentences.
The knowledge representation will be described in Section 5.
The conceptual similarity function serves as a metric to partition the set of words 
K and to perform the encoding of the words. It willbe described in Section 7.
<!--. NH 1-->
</P>
<H2>
4.
An Interactive Design Environment
<!--. PP -->
</H2>
<P>
From the previous sections, it becomes clear that to design
iconic languages,
we need to provide the models and tools for representing the semantic 
knowledge of iconic languages, applying powerful inference 
mechanisms capable of interpreting the underlying meanings, combining icons in 
order to infer new meanings, and giving explanations regarding the rationale
used during such inferences. 
The designer can then employ these models and tools to
design a customized iconic language.
<!--. PP -->
</P>
<P>
In this section we describe the architecture
of such an interactive design environment.
The meanings of individual icons, as we will discuss in more detail in Section 5,
can be represented through a frame structure with semantic attributes 
created according to the metaphors appropriate for the context of this visual 
language.  The iconic sentence with more than just one icon can still be 
represented by the same structure, but it turns out to be very difficult 
to determine its attributes.  Indeed, the only thing that can be automatically 
derived from the semantics of the icons in an iconic sentence is a list of 
values belonging to the frames of these icons. The problem is that individual 
icons in the iconic sentence provide only a portion of the semantics. The 
rest of it is a result of the combination of these icons, and cannot be 
detected without a global semantic analysis of the sentence.
<!--. PP -->
</P>
<P>
In order to perform such a kind of analysis, the interaction of the 
designer, at first, seems to be of vital importance. But at the same time, 
the nature of the problem suggests that a lot of knowledge involved in 
that process can be formalized, together with a set of iconic operators that 
will support general semantic inferences, in order to derive all the possible 
meanings of the iconic sentences and submit them for the approval by the
designer. In this way, the designer can perform a more effective semantic
analysis by interacting with an environment that would allow the exploration of a number of
solutions that might not have come to mind intuitively.
<!--. PP -->
</P>
<P>
Our approach gives a more complete representation of the knowledge
in an individual icon, representing not only static knowledge but also the dynamic 
aspects of it.  The interactive design environment provides a set of formal iconic operators to perform 
inferences and derive possible meanings of iconic sentences, starting from
the knowledge available from the component icons.
<p>
<!--. PP -->
</P>
<P>
The architecture of the interactive design environment, which has been implemented on an IBM PC, is shown in Figure 2. It consists of a
knowledge base, an inference engine, the SIL iconic system 
<!--. [[ -->
Chang Tauber
<!--. ]] -->
and the user interface. In the knowledge base we store the semantics of 
icons and iconic operators. The inference engine applies the iconic 
operators to derive new meanings of the iconic sentence which is given as 
input through the SIL's visual sentence parser.
The user interface allows the user to provide feedback to the system
in choosing the possible meanings of icons and iconic sentences.
<!--. NH 1-->
</P>
<H2>
5.
Knowledge Representation
<!--. PP -->
</H2>
<P>
When choosing a model for representing knowledge for iconic languages, we should
consider the following.  We need to provide a unified representation for
words, icons and iconic sentences, which are all considered as <I>objects</I>.
The representation should allow ambiguity because we want to capture all
the possible meanings of an icon according to several
metaphors. Moreover, each object carries both dynamic and static knowledge. 
This is particularly true for the icons where each associated action 
must be represented in some way.  Finally, the
knowledge representation should have characteristics that will
facilitate an inference algorithm (see Section 6) to perform 
the inferences that are needed.
<!--. PP -->
</P>
<P>
A more refined model should also be capable of classifying the
meanings associated with an object in a hierarchical way, because a concept at a certain abstraction level
can be more descriptive for the object than another one. For example, the
object &quot;orange&quot; is both an object with a circular shape and an object with
the color &quot;orange&quot;, but the latter is often more descriptive for the
object &quot;orange&quot;.  Hence, we need to provide a parameter indicating
how appropriate is a semantic interpretation in describing a 
given object.
Also, each icon should have a (preferably unique) primary meaning associated with it,
which serves as an index for the icon.
<!--. PP -->
</P>
<P>
In order to achieve the above, we use an approach 
for knowledge representation, combining the frame-based representation with features of the <I>theory 
of conceptual dependency</I>
<!--. [[ -->
Conceptual Dependency: A theory of natural language understanding
<!--. ]] .-->
<!--. PP -->
</P>
<P>
The frame based representation is very suitable, because describing an icon through a 
set of attributes is a natural way to represent knowledge carried by the icon.
On the other hand, as mentioned above, we need also to represent the dynamics that
are depicted in the icon, because they can be very helpful in compacting a large amount 
of knowledge in the icon. The theory of conceptual dependency
provides the means to represent the conceptual meanings of sentences expressed
in a textual language, capturing both the static and the dynamic aspects.
Since an iconic sentence can be regarded as a visual representation of a
sentence in a textual language, both visual and textual languages have underlying conceptual
meanings to be captured and opportunely represented. Therefore, in both 
disciplines the common goal is to have
formal structures for representing knowledge in such a way that supports
manipulation and inferencing to detect similarities in meanings
and conceptual relationships among these structures.
<!--. PP -->
</P>
<P>
In what follows, we explain in detail
how the frame-based representation can be augmented by
the Conceptual Dependency theory for representing knowledge for iconic languages.
<!--. NH 2-->
</P>
<H2>
5.1.
The Frame-Based Representation
<!--. PP -->
</H2>
<P>
The knowledge underlying an icon is represented using not only conceptual 
meanings but also many other kinds of metaphors depending on the particular 
context of the visual language in question.
According to these metaphors, we set one or more attributes in a frame 
structure which will be used to describe the semantics of an icon.
In the case of the Minspeak<sup>TM</sup> visual languages we have made use of the metaphors from the <I>Types of Semantic Relationships</I> diagram
<!--. [[ -->
Baker, Models and Semantic Relationships 
<!--. ]] ,-->
and directly translated those metaphors into a frame structure.
For instance, the metaphor &quot;quantity&quot;  can be expressed through
the two attributes &quot;mass_quantity&quot; and &quot;count_quantity&quot;. If we want 
to express the knowledge in the icon &quot;elephant&quot;, among the various attributes, 
we can fill the attribute &quot;mass_quantity&quot; with the value &quot;big&quot;.
In the following, the frame structure representing part of the
semantics of an icon is given.  Only the macro-attributes at the first nested 
level are included to clearly illustrate the correspondence with the
metaphors.
<p>
<pre>
<!--. nf -->
<BR>
<!--. ls 1-->
 . SOUND				. ACTIVITY
<BR>
  .. Alphabetic abbreviation		.. Use
<BR>
  .. Sound              
<BR>
  .. Rhyme				. EMOTION
<BR>
  .. Recall				.. What does it  recall
<BR>
<p>
 . TIME					. CONVENTION
<BR>
  .. Time sequencing		 	.. Linguistic
<BR>
					.. Cultural
<BR>
 . SHAPE                                 
<BR>
  .. Type of Shape			. QUANTITY 
<BR>
					.. Mass
<BR>
 . COLOR				.. Count
<BR>
  .. Color                              
<BR>
					. IS_A 
<BR>
 . LOCATION			 	.. Abstract
<BR>
  .. Where				.. Concrete
<BR>
<p>
 . QUALITY                               
<BR>
  .. Quality                             
<BR>
<!--. fi -->
<BR>
</pre>
<!--. ls 2-->
<!--. PP -->
</P>
<P>
We will use this structure for representing knowledge about
different objects: words to be encoded, icons, or iconic sentences.
The frame of an object is filled with the values of the attributes 
describing the object, according to a set of metaphors, together with a 
<I>fuzzy parameter</I> in the range [0,1], denoted by <img src=minsfig1/omega.gif>.More precisely, this semantic parameter indicates the importance and 
appropriateness of the value of the attribute for describing the given object. 
In the previous example on the object &quot;orange&quot;,
the <img src=minsfig1/omega.gif> parameter for the value &quot;orange&quot; in the attribute &quot;color&quot; should be higher than the <img src=minsfig1/omega.gif> parameter for the value &quot;circular&quot; in the attribute &quot;shape&quot;, because it is more intuitive and appropriate to 
think of an orange as an object having orange color than as an object having 
circular shape.
<!--. PP -->
</P>
<P>
In the following, we present three example of frames,
where the icons THERMOMETER and MOUNTAIN appear in the keyboard
shown in Figure 1, and the word COLD is a derived concept.
<p>
<!--. ls 1-->
<!--. nf -->
<BR>
<pre>
<B>Example 1</B>: icon THERMOMETER
<BR>
<p>
	shape:			bar				0.8
<BR>
	color:			red				0.8
<BR>
	location:		wall				0.6
<BR>
				emergency box			0.7
<BR>
				weather bureau			0.7
<BR>
	quality:		mercury				0.6
<BR>
	use:			takes the temperature		0.9
<BR>
	what does it recall:	flu				0.9
<BR>
				warm				0.8
<BR>
				cold				0.8
<BR>
	cultural conv.:		forecast			0.6
<BR>
	mass:			normal				0.2
<BR>
	quantity:		single				0.6
<BR>
	is_a_concrete:		tool for temperature		0.9
<BR>
<p>
<B>Example 2</B>: word COLD
<BR>
<p>
	time sequencing:	winter				0.9
<BR>
	color:			white				0.9
<BR>
	location:		north				0.8
<BR>
	use:			to keep				0.6
<BR>
	what does it recall:	snow				0.8
<BR>
				cold				0.9
<BR>
				Christmas			0.8
<BR>
				death				0.7
<BR>
	is_an_abstract		cold				0.8
<BR>
<p>
<B>Example 3</B>: icon MOUNTAIN
<BR>
<p>
	alphabetical abbr.:	MT				0.7
<BR>
	sound:			echo				0.6
<BR>
				silence				0.7
<BR>
	rhyme:			mounting			0.6
<BR>
	time sequencing:	winter				0.9
<BR>
				summer				0.7
<BR>
	shape:   		pyramid				0.6
<BR>
				triangle			0.4
<BR>
	color:			white				0.7
<BR>
				green				0.6
<BR>
	quality:		rock				0.6
<BR>
				snow				0.6
<BR>
	use:			to ski				0.7
<BR>
				to relax			0.7
<BR>
				to explore			0.5
<BR>
	what does it recall:	clean air			0.8
<BR>
				cold				0.9
<BR>
				fatigue				0.8
<BR>
				sport				0.8
<BR>
				majestic			0.7
<BR>
	linguistic conv.:	Mohammed			0.5
<BR>
	mass:			very big			0.7
<BR>
	quantity:		two				0.6
<BR>
	is_an_abstract:		stately person			0.7
<BR>
	is_a_concrete:		peak				0.8
<BR>
</pre>
<p>
<!--. fi -->
<BR>
<!--. ls 2-->
<!--. NH 2-->
</P>
<H2>
5.2.
Conceptual Dependency
<!--. PP -->
</H2>
<P>
Conceptual Dependency (CD) is a theory of natural language and of natural
language processing
<!--. [[ -->
Conceptual Dependency: A theory of natural language understanding
<!--. ]] .-->
language processing.  It was created by Schank and can be employed for the
construction of computer programs capable of understanding sentences of  
natural language, summarizing them, translating them into another language and 
answering questions about them. The basic axiom of the theory is:
<!--. PP -->
</P>
<P>
<I>For any two sentences that are identical in meaning, regardless
of language, there should be only one representation</I>.
<!--. PP -->
</P>
<P>
Thus, any information in the sentence that is implicit must be made explicit 
in the representation of the meaning for that sentence.
<!--. PP -->
</P>
<P>
Through this theory, understanding of concepts is performed by mapping linear
strings of words into conceptual structures. A conceptual structure is a kind 
of semantic net.  It is defined as a network of concepts, where some classes
of concepts may have specific relationships with other classes of concepts.
<!--. PP -->
</P>
<P>
The meaning of a linguistic proposition is called a conceptualization or CD 
form.
A conceptualization can be active or stative.
An active conceptualization consists of the following slots: actor, action, 
object, and direction. The latter is subdivided into source and destination.
A stative conceptualization consists of the following slots: object, state, 
and value. 
<!--. PP -->
</P>
<P>
From this theory of
Conceptual Dependency, we have derived rules and CD forms suitable for our purpose.
In our adaptation of this theory,
rules for concepts combination use the following conceptual categories
<!--. [[ -->
Conceptual Dependency: A theory of natural language understanding
<!--. ]] :-->
<p>
<B>PPs: Picture Producers.</B> Only physical objects are PPs. They may serve 
in the role of objects as well as source, destination and recipient of 
actions.
<p>
<B>ACTs: Actions.</B> Actions can be done by an actor to an object. 
<p>
<B>LOCs: Locations.</B> They are considered to be coordinates in space and can 
modify conceptualizations as well as serve as sources and destinations.
<p>    
<B>Ts: TIMES.</B> The time is considered to be a point or a segment on a time line.
<p>
<B>AAs: Action Aiders.</B>  AAs are modifications of features of an action.
<p>
<B>PAs: Picture Aides, or Attributes of an Object.</B>  A PA is an attribute 
characteristic such as color or size plus a value for that characteristic, 
a number of them can be used for describing a physical object.
<p>
<!--. PP -->
</P>
<P>
Here are some rules through which classes of concepts can combine
<!--. [[ -->
Conceptual Dependency: A theory of natural language understanding
<!--. ] -->
<!--. [ -->
Identification of Conceptualization Underlying Natural Language
<!--. ]] .-->
<p>
<!--. nr -->
<B>Rule 1. Certain PPs Can ACT.</B> For example, the sentence &quot;Kevin walked&quot;  
may be represented using the primitive act PTRANS (A list of primitive actions
is given later) as
<!--. nf -->
<BR>
<!--. ls 1-->
<p>
		Actor:          Kevin
<BR>
		Action:         PTRANS
<BR>
		Object:         Kevin
<BR>
		Direction:      From: Unknown	To: Unknown 
<BR>
<!--. ls 2-->
<p>
<!--. fi -->
<BR>
<!--. nr -->
The kind of ACT and the PP performing it can only be determined in each case
by the semantic nature of these two objects.
<p>
<!--. nr -->
<B>Rule 2. PPs and Some Conceptualizations Can Be Described By an 
Attribute .</B> For example, the sentence &quot;Nancy is heavy&quot; may be represented
using the following stative conceptualization:
<!--. nf -->
<BR>
<!--. ls 1-->
<p>
		Object:         Nancy
<BR>
		State:          WEIGHT
<BR>
		Value:          Above the Average
<BR>
<!--. ls 2-->
<p>
<!--. fi -->
<BR>
<!--. nr -->
<B>Rule 3. ACTs Have Objects.</B> For example, the sentence 
&quot;Perry Kicked the cat&quot; may be represented using the primitive action PROPEL
(Physical force applied, see below) as
<!--. nf -->
<BR>
<!--. ls 1-->
<p>
		Actor:          Perry
<BR>
		Action:         PROPEL
<BR>
		Object:         cat
<BR>
		Direction:      From: Unknown	To: Unknown 
<BR>
<!--. ls 2-->
<p>
<!--. fi -->
<BR>
<!--. nr -->
<B>Rule 4. ACTs Have Direction.</B> For example, the sentence 
&quot;Bill fell from the ladder&quot; may be represented using the primitive action 
PTRANS (see below) as
<!--. nf -->
<BR>
<!--. ls 1-->
<p>
		Actor:          Bill
<BR>
		Action:         PTRANS
<BR>
		Object:         Bill 
<BR>
		Direction:      From: ladder	To: ground
<BR>
<!--. ls 2-->
<p>
<!--. fi -->
<BR>
<!--. nr -->
<B>Rule 5. ACTs Have Recipients.</B> For example, the sentence 
&quot;John donated blood to the Red Cross&quot; may be represented using the primitive 
action ATRANS (see below) as
<!--. nf -->
<BR>
<!--. ls 1-->
<p>
		Actor:          John
<BR>
		Action:         ATRANS
<BR>
		Object:         blood 
<BR>
		Direction:      From: John	To: Red Cross
<BR>
<!--. ls 2-->
<p>
<!--. fi -->
<BR>
<!--. nr -->
     
<B>Rule 6. ACTs Can Have Instrumental ACTs.</B> For example, 
&quot;John hit Bill with his hand&quot; will be represented as 
<!--. nf -->
<BR>
<!--. ls 1-->
<p>
		Actor:          John
<BR>
		Action:         PROPEL
<BR>
		Object:         Bill 
<BR>
		Instrument:     Actor:    John
<BR>
				Action:   MOVE
<BR>
				Object:   hand
<BR>
				Direction: From: John	To: Bill
<BR>
<!--. ls 2-->
<p>
<!--. fi -->
<BR>
<!--. PP -->
</P>
<P>
The use of a set of primitive actions reduces the complexity of 
inferences to be made as the inference rules need only be written once for 
any ACT rather than many times for each verb that references that ACT.
Often an action can be expressed through more than just one verb, but
for our purposes we want to get rid of this redundancy and have only a 
general representation for sentences with the same conceptual meaning.
Furthermore, this representation makes more evident the similarities in meaning
among sentences than the textual representation does.
<!--. PP -->
</P>
<P>
In the following a list of the most important primitive ACTs is given
<!--. [[ -->
Conceptual Dependency: A theory of natural language understanding
<!--. ] -->
<!--. [ -->
Identification of Conceptualization Underlaying Natural Language
<!--. ]] :-->
<p>
<!--. nr -->
ATRANS is the  transfer of an abstract relationship, such as possession, 
ownership or control.
<p>
PTRANS is the transfer of the physical location of an object.
<p>
PROPEL is he application of a physical force to an object.
<p>
MOVE is the movement of a body part of an animal by that animal.
<p>
GRASP is the grasping of an object by an actor.
<p>
INGEST  is the taking of an object by an animal to the inside of that 
animal.
<p>
EXPEL is the expulsion of an object from the body of an animal into the 
physical world. 
<p>
MTRANS is the transfer of mental information between animals or within an 
animal.
<p>
MBUILD is the construction by an animal of new information from old 
information.
<p>
SPEAK is the action of producing sounds. 
 
ATTEND is the action of attending or focusing a sense organ toward a 
stimulus. For example the verb &quot;listen&quot; means ATTEND ear, and the verb &quot;see&quot;
means ATTEND eye.
<!--. PP -->
</P>
<P>
As far as stative CD forms are concerned, they can be used 
for representing  statements requiring stative conceptualization. 
Attached to each  attribute-value pair we may have scales to show the range
of the value for that attribute.
<!--. NH 2-->
</P>
<H2>
5.3.
The Augmented Frame-Based Representation
<!--. PP -->
</H2>
<P>
As discussed above, compacting semantic information in an icon is accomplished by adding some  
meaningful dynamic aspects to the icon image.  For
example, if an icon image of the sun was designed to represent words such
as &quot;yellow&quot; and &quot;bright&quot;, we may enrich the icon by designing a rising sun to   
encompass also some other words such as &quot;dawn&quot;, &quot;morning&quot; and  
&quot;start&quot;.  The newly added meanings can be represented in the 
knowledge base in the same way as CD theory would represent the sentence 
&quot;The sun is rising&quot; by using the primitive action PTRANS 
<p>
<!--. [[ -->
Conceptual Dependency: A theory of natural language understanding
<!--. ]] -->
as follows: 
<p>
<!--. nf -->
<BR>
<!--. ls 1-->
		Actor:          Sun
<BR>
		Action:         PTRANS
<BR>
		Object:         Sun
<BR>
		Direction:      From: Sea	to: Sky
<BR>
<!--. fi -->
<BR>
<!--. ls 2-->
<!--. PP -->
</P>
<P>
Such a structure can be integrated into the frame structure 
described above by adding some more slots. These new attributes are
very useful to infer additional meanings about the icon, such as &quot;The sun is
rising to the sky&quot; which will yield the new value &quot;sky&quot; for the attribute 
&quot;where&quot;, thus allowing the designer to encode additional concepts and words belonging 
to the given context. For the example of the rising_sun icon, other than 
filling the dynamic attributes as discussed above, the semantic knowledge is 
represented by the attributes of the frame structure for the rising_sun which
now also includes the new value &quot;sky&quot; inferred by the presence of the CD 
attributes:
<p>
<!--. nf -->
<BR>
<!--. na -->
<!--. ls 1-->
		Color:		Yellow  
<BR>
		Time :		Morning        
<BR>
		Shape:		Circular
<BR>
		Mass :		Big     
<BR>
		Use  :			Energy   
<BR>
		<B>Where:		Sky</B>     
<BR>
<!--. fi -->
<BR>
<!--. ls 2-->
<!--. ad -->
<!--. PP -->
</P>
<P>
We can complete the semantic knowledge by adding the semantic parameter values.
<!--. PP -->
</P>
<P>
The construction of the frame (including the CD form slots) for each single 
word to be encoded by the visual language, is done by the
designer. The frame for each single icon is obtained by inheriting the frame 
of the word directly associated with the icon 
<!--. [[ -->
Deriving the Meaning of Iconic Sentences
<!--. ]] ,-->
with some more information added due to the additional meanings conveyed by the 
icon image.
As far as the frame for an iconic sentence
is concerned, we need to perform inferences on the 
augmented frames (basic frames plus CD slots with newly inferred attribute values)
of the icons composing the
sentences.  In Section 6 we will discuss the formal criteria to perform such
inferences. However, having the augmented frames of the single icons 
available, we can already derive a skeleton of the frame for the iconic 
sentence using the following algorithm.
The input are the frames of two icons v<sub>i</sub> and v<sub>j</sub>,and the output is the frame of the iconic sentence v<sub>i</sub>v<sub>j</sub>.<p>
<!--. nf -->
<BR>
<!--. ls 1-->
<pre>
<B>Procedure Construct_Frame</B>(frame(v<sub>i</sub>),frame(v<sub>j</sub>),frame(v<sub>i</sub>v<sub>j</sub>))<BR>
{
<BR>
<B>for</B> each matching value do
<BR>
	<B>if</B>  the matching value appears in the frames 
<BR>
		  input the common attribute A with <img src=minsfig1/omega.gif> <BR>
		  parameters equal to <img src=minsfig1/omega.gif><sub>i</sub> and <img src=minsfig1/omega.gif><sub>j</sub>, respectively,<BR>
	<B>then</B> fill the attribute A of the resulting frame with 
<BR>
		the matching value and set the <img src=minsfig1/omega.gif> parameter to <BR>
<p>
<!--
	{OMEGA<sub>i</sub>*[1+{|OMEGA<sub>i</sub>-OMEGA<sub>j</sub>|}over2]+OMEGA<sub>j</sub>*[1-{|OMEGA<sub>i</sub>-OMEGA<sub>j</sub>|}over2]}over2. 
-->
	<img src=minsfig1/t1.eq.gif>
<BR>
	<B>else if </B> the matching value appears in the frames 
<BR>
		input two different attributes A and B with <img src=minsfig1/omega.gif> <BR>
		parameters equal to <img src=minsfig1/omega.gif><sub>i</sub> and <img src=minsfig1/omega.gif><sub>j</sub>, respectively<BR>
	    <B>then</B> fill the attributes A and B of the resulting
<BR>
	 	frame with the matching value and set the <img src=minsfig1/omega.gif> <BR>
		parameter to 
<BR>
<!--{ OMEGA sub i  * [ 1 + { | OMEGA sub i  - OMEGA sub j | } over 2 ] + OMEGA sub j  * [ 1 - { | OMEGA sub i  - OMEGA sub j | } over 2 ] } over 2
-->
<p>
	<img src=minsfig1/t2.eq.gif><br>

let <img src=minsfig1/omega.gif><sub>1</sub> be the minimal <img src=minsfig1/omega.gif> parameter computed at this step,<BR>
<B>for</B> each value in the frame of v<sub>i</sub> and not in the frame of <BR>
	v<sub>j</sub> with <img src=minsfig1/omega.gif> parameter greater than a threshold D<sub>1</sub> <B>do</B><BR>
	fill each attribute of the resulting frame in which 
<BR>
	such values appear with the value itself and the <img src=minsfig1/omega.gif> <BR>
	parameter multiplied by <img src=minsfig1/omega.gif><sub>1</sub>;<BR>
let <img src=minsfig1/omega.gif><sub>2</sub> be the minimal <img src=minsfig1/omega.gif> parameter computed at this step,<BR>
<B>for</B> each value in the frame of  v<sub>j</sub> and not in the frame of<BR>
 	v<sub>i</sub> with <img src=minsfig1/omega.gif> parameter greater than a threshold D<sub>2</sub> <B>do</B><BR>
	fill each attribute of the resulting frame in which 
<BR>
	such values appear with the value itself and the <img src=minsfig1/omega.gif> <BR>
	parameter multiplied by <img src=minsfig1/omega.gif><sub>2</sub>;<BR>
}
<BR>
</pre>
<!--. fi -->
<BR>
<!--. ls 2-->
<!--. PP -->
</P>
<P>
The above algorithm, applied to the object icons THERMOMETER and MOUNTAIN in 
both ordering sequences, yields the following frames: 
<p>
<!--. nf -->
<BR>
<pre>
<!--. ls 1-->
iconic sentence THERMOMETER/MOUNTAIN
<BR>
	time sequencing:	winter			0.686475
<BR>
	use:			takes the temperature	0.76275
<BR>
	what does it recall:	flu			0.76275
<BR>
				cold			0.8475
<BR>
	is_a_concrete:		tool for temperature   	0.76275 
<BR>
D<sub>1</sub>=0.81; D<sub>2</sub>=0.85<BR>
<p>
iconic sentence MOUNTAIN/THERMOMETER
<BR>
	time sequencing:	winter			0.76725
<BR>
	use:			takes the temperature	0.690525
<BR>
	what does it recall:	flu			0.690525
<BR>
				cold			0.8525
<BR>
	is_a_concrete:	tool for temperature    	0.690525
<BR>
D<sub>1</sub>=0.81; D<sub>2</sub>=0.85<BR>
</pre>
<!--. ls 2-->
<!--. fi -->
<BR>
<!--. PP -->
</P>
<P>
In order to obtain a complete representation of the semantics of 
the iconic sentences that these frames represent, we need to enrich 
the frames according to the semantics conveyed by the icons
composing the sentence as they were viewed as a whole.
This will be discussed in the following section.
<!--. NH 1-->
</P>
<H2>
6.
An Inference Algorithm
<!--. PP -->
</H2>
<P>
Our goal here is to build an inference algorithm to derive the meanings 
associated with iconic sentences from the meanings associated with the
individual icons forming the sentences.
In order to achieve this goal, we will make
use of the Icon Algebra operators and some principles described in the 
Theory of Conceptual Dependency  
<!--. [[ -->
Conceptual Dependency: A theory of natural language understanding
<!--. ]] .-->
<!--. PP -->
</P>
<P>
In our approach, we have formalized the
semantics of a set of Icon Algebra operators which, combined with
the primary meanings of the component icons, give the possible meanings
of the iconic sentence. The derived meanings are submitted to the designer who will 
decide whether to accept or discard the new meanings.  He may also perform 
some actions such as assigning the <img src=minsfig1/omega.gif> parameter or the appropriate slotto fill the new information in.
<!--. PP -->
</P>
<P>
However, before going into the process of inferring the semantic knowledge
of the visual sentence, the inference algorithm may need to perform some inferences 
on the single icons forming the sentence. In fact, especially for the 
frame slots for the dynamic knowledge (the CD slots) that may contain
some implicit meanings, we need to make that explicit in the frame. In
order to do that, we need to attach to each primitive ACT certain
inference-generating procedures to compute the consequences of that 
primitive ACT.
For example, some of the consequences for the primitive ACT PTRANS may be 
computed by the following lisp function
<!--. [[ -->
Conceptual Dependency: A theory of natural language understanding
<!--. ]] :-->
<!--. ps 8-->
<!--. nf -->
<BR>
<!--. ls 1-->
<p>
<pre>
(Defun PTRANS-CONSEQ() 
<BR>
<!--. in 2-->
  (NOTICE $(ACTOR) &quot;CD&quot;) 
<BR>
  (ADD-CONSEQ (IS-AT (OBJECT)(TO))) <BR>
  (COND ((FROM)(NOTICE(ACTOR) <BR>
<!--. in 4-->
    (ADD-CONSEQ 
<BR>
<!--. in 5-->
     (NEGATE (IS-AT (OBJECT)(FROM)))))))) <BR>
<!--. fi -->
<BR>
</pre>
<!--. ls 2-->
<!--. in 0-->
<!--. PP -->
</P>
<P>
The operator '$' catches the value of the slot to which it is applied. The 
function NOTICE notifies an object (first argument) that something has happened 
(second argument). Thus, in its first use, NOTICE notifies the ACTOR that a 
PTRANS has taken place.  The details of this action are described in the CD 
form given as second argument. The function IS-AT notifies the change of 
location for the object which has moved. Finally, the
COND instruction checks whether the object left from a source (in 
this case the slot FROM would have a positive filler). If that was the case,
the function NEGATE cancels the belonging of the object from the old position.
This kind of inference procedures will enrich the frames originally 
built for the icons. In what follows, we will see how the inference engine
will act on these enriched frames to derive the meanings for iconic sentences.
<p>
<!--. PP -->
</P>
<P>
The design of this part of the inference engine is essentially a 
parser that parses iconic sentences into single frames. The iconic sentences 
to be parsed are to be viewed as having one of the icon algebra operators in
them. The algorithm will parse them, in turn, with all of the operators 
described in Section 2.
For each iconic operator, we can define a set of primitive words whose
meaning can be viewed as
a textual representation of the meaning of the operator. Put it
in another way, these words represent values of attributes describing the
operators such that, when combined with attributes describing the icons in the
sentences, produce  candidate attribute values for the frames being built,
e.g. the frames representing the iconic sentences.  
<!--. PP -->
</P>
<P>
An outline of the parsing algorithm is presented in the following.
<p>
<!--. ls 1-->
<pre>
<B>Procedure Parse</B>
<!--. br -->
<BR>
{
<!--. br -->
<BR>
<B>1.</B> Select a set of meaningful attributes from the frames of the icons
in the sentence.  These will be the ones whose
<img src=minsfig1/omega.gif> parameters have values greater than a prefixed threshold. Each time,only one attribute per object icon is selected. 
<!--. br -->
<BR>
<B>2. for</B> pair of meaningful attributes, one per each frame, and 
<!--. nf -->
<BR>
<B>	for</B> each iconic operator,
<BR>
	   <B>apply</B> the iconic operator to generate a candidate 
<BR>
	   attribute value for the frame being constructed; 
<BR>
	   <B>submit</B>  the new value to the designer;
<BR>
}
<BR>
</pre>
<!--. fi -->
<BR>
<!--. ls 2-->
<p>
<!--. PP -->
</P>
<P>
The parser starts by examining index attributes, which are
obtained by applying the IDX operator, whose implementation simply provides
the attribute value with the maximum <img src=minsfig1/omega.gif> parameter. At the end of thisstep, every
attribute whose value is above the threshold, will have been combined with
the corresponding attributes of the other object icons, according to all the
icon operators available. For iconic sentences
of length greater than 2, the parsing will be recursive, and more than
one icon operator may be applied to the sentence. In other words, the  
parsing is performed by applying the first iconic operator to the first two 
icons in the sentence, then a new iconic operator is applied to the resulting frame and the third icon in the
sentence, and so on.
<!--. PP -->
</P>
<P>
The semantic definitions of the iconic operators are given below. 
<!--. PP -->
</P>
<P>
1. The operator CON of Contextual Interpretation refines the meaning of the  
first icon in the context of the second icon. Therefore
we use the attribute word IN_THE_CONTEXT_OF or briefly IN_THE to describe its 
semantics. For example,
we can derive &quot;Food_IN_THE_CONTEXT_OF_Morning&quot; as a 
result of
applying CON to X.[is]apple.[is_a_concrete]food and 
Y.[is]rising_sun.[time]morning. At this point, the designer should decide which 
slot in the frame for the iconic sentence should contain the new value. This 
new attribute value should enhance the opportunities to encode new words in the 
language.  In fact, a similarity with the frame for the word &quot;breakfast&quot; can be detected 
using the similarity function introduced in the next section.
However, the user may decide to change the new value directly to &quot;breakfast&quot; and
put this value in the right slot.
<!--. PP -->
</P>
<P>
2. The operator COM of Combination may have the word attributes MERGED_WITH, 
AND, or WITH, because it combines the meanings of two object icons.
For example, combining the icons &quot;Jump&quot; and &quot;Volt&quot; by applying COM to 
X.[is]jump.[recall]fast and Y.[is]volt.[quality]fast,
we obtain the slot value &quot;fast_MERGED_WITH_fast&quot; which implicitly means &quot;hurry&quot;.
Again, the designer can make the meaning explicit by directly assigning it
to the object, or by performing the similarity inference.  In the later case, 
the similarity with the frame of the word 'hurry' should be detected.
<!--. PP -->
</P>
<P>
3. For MAR, the marking operator, we may associate the word attribute 
AS_MARKER_OF or simply OF, 
because it uses the first icon as a characteristic of the
second icon. Thus for example, the application of MAR to 
X.[is]rainbow.[recall]color and Y.[is]chest.[quality]treasure will lead to the 
attribute value &quot;color_OF_treasure&quot;. After the marking operation, the 
similarity with the word &quot;gold&quot; becomes more evident.
<!--. PP -->
</P>
<P>
4. The operator ENH &quot;enhancement&quot; emphasizes the meaning of the 
first icon by partially incorporating the meaning of the second icon. So we
may associate the word attribute ENHANCED_BY, because it enhances the 
meaning of the first icon with that of the second icon.  Thus
enhancing X.[is]thermometer.[use]temperature by Y.[is]thumbs_down.[recall]low 
will lead to the attribute value &quot;Temperature_ENHANCED_BY_low&quot; which means cold.
<!--. PP -->
</P>
<P>
5. Finally, the operator INV &quot;Inversion&quot; performs semantic inversion on the  
icon in the sentence (it is noted that NOT is not binary).  We have associated it
with the word attributes  INVERTED, OPPOSITE_OF, NOT, or WITHOUT, so that by 
applying INV to X.[is]god.[recall]true which is the index attribute value for 
&quot;God&quot;, we get &quot;OPPOSITE_OF_true&quot;, &quot;NOT_true&quot;, or &quot;INVERTED_true&quot;, which 
implicitly means false.
<!--. NH 1-->
</P>
<H2>
7.
The Conceptual Similarity Function 
<!--. PP -->
</H2>
<P>
As discussed above, one critical issue is to find an adequate similarity 
function.   The techniques for measuring similarity between two objects 
have been studied in statistics, econometrics,  psychology 
and sociology.   These techniques include factor analysis,  multi-variate analysis, least squares, 
classification,  component analysis, and clustering
<!--. [[ -->
Bartholomew
<!--. ], -->
<!--. [ -->
Exploring hyperspace
<!--. ], -->
<!--. [ -->
Miller
<!--. ], -->
<!--. [ -->
Weiss
<!--. ], -->
<!--. [ -->
Hunter
<!--. ], -->
<!--. [ -->
Bendix
<!--. ], -->
<!--. [ -->
Romesburg
<!--. ]] .-->
Classification has been widely studied in information retrieval
<!--. [[ -->
Chauncey
<!--. ], -->
<!--. [ -->
Szalay
<!--. ], -->
<!--. [ -->
Sparck Jones
<!--. ]] .-->
<!--. PP -->
</P>
<P>
All these techniques are based on the principle of constructing a
data matrix in which the individuals to be compared are measured
along certain attributes.  Each individual can correspond to
a row and each column reports the value of an attribute for each
individual.  These attributes are called the anchors on which the
similarity is based.
<!--. PP -->
</P>
<P>
In this section we will describe a similarity function based on 
comparisons of attributes. We define a function <B>g</B> which takes as input 
two objects O<sub>i</sub> and  O<sub>j</sub>  and returns a value in [0,1] indicating how conceptually similar the objects are. 
As the meaning of an object is expressed by its frame, the function <B>g</B> 
works on the frames F<sub>i</sub> and F<sub>j</sub> representing the objects O<sub>i</sub> and O<sub>j</sub> as described in the previous sections, taking into account the matching values and their <img src=minsfig1/omega.gif> parameters. As said above, the similarity between two objects is usually based upon the number of the matching values. 
In our approach, instead, what is important is the significance of the matching
values  expressed by the <img src=minsfig1/omega.gif> parameter. Thus, it can be enough even having just one matching value between two objects, but very significant for both, in order
to establish a high degree of similarity. 
<!--. PP -->
</P>
<P>
The function <B>g</B> will take into account the following three types of 
matching:
<p>
1) Real match.  We will say that there is a real match when two objects have 
the same value in a same attribute of their frame. For example the frames of 
the words BLOOD and FIRE both have  the value &quot;red&quot; in the attribute &quot;color&quot;. 
This is the most important type of matching since both objects can be 
thought in terms of the same attribute.
<p>
2) Diagonal match.  We will say that there is a diagonal match when two object 
have the same value in different attributes of their frame. For example the 
frame of the word MOUNTAIN has the value &quot;rain&quot; in the attribute &quot;rhyme&quot; while 
the frame of the word CLOUD has the value &quot;rain&quot; in the attribute &quot;what does 
it recall&quot;. This type of matching is less significant than the real 
match, but it is anyway important in the comparison of two objects because both 
objects recall the same meaning.
<p>
3) Mismatch.  We will say that there is a mismatch when two objects have 
the same attribute empty. For example the fact that the frames of abstract 
objects have attributes as &quot;shape&quot; empty could be considered a small index of 
similarity. Anyway, the mismatch will contribute a very small value to the 
similarity and basically it serves to distinguish this particular case from the 
ones in which there is no-match, i.e. different values in the same 
attribute or just one empty.
<!--. PP -->
</P>
<P>
Now we are ready to show the formulation of the function <B>g</B>. First of all 
we construct the extended frames F<sub>i</sub><sup>*</sup> and F<sub>j</sub><sup>*</sup> (on which the function <B>g</B> will work) by a simple procedure 
which, for each value in the frame 
F<sub>i</sub> checks if that value appears in the frame F<sub>j</sub> within adifferent attribute introducing some new fictitious attributes in order to 
allow <B>g</B> to work comparing the same attributes. As an example, with 
reference to the following situation:
<p>
<!--. TS -->
<table cellspacing=1 border=1>
<tr><td></td><th>Attribute<sub>1</sub></th><th>Attribute<sub>2</sub></th>
<tr><td> object1 <td>val<sub>1</sub><img src=minsfig1/omega.gif><sub>1</sub> <td> val<sub>2</sub><img src=minsfig1/omega.gif><sub>2</sub>
<tr><td> object2 <td>val<sub>1</sub><img src=minsfig1/omega.gif><sub>3</sub> <td> val<sub>1</sub><img src=minsfig1/omega.gif><sub>4</sub>
</table>
<pre>                  March 15, 1997</pre>

<p>
<!--. PP -->
</P>
<P>
The extension will produce:
<p>
<!--. TS -->
<table cellspacing=1 border=1>
<tr><td></td><td>   Attribute1     <td>          Attribute2     <td>           Attribute*
<tr><td> object1<td>   val<sub>1</sub><img src=minsfig1/omega.gif><sub>1</sub>  <td> val<sub>2</sub><img src=minsfig1/omega.gif><sub>2</sub>  <td> val<sub>1</sub><img src=minsfig1/omega.gif><sub>1</sub>
<tr><td> object2 <td>  val<sub>1</sub><img src=minsfig1/omega.gif><sub>3</sub>  <td>
val<sub>1</sub><img src=minsfig1/omega.gif><sub>4</sub>  <td>
val<sub>1</sub><img src=minsfig1/omega.gif><sub>4</sub>
</table>

<pre>                       March 15, 1997

</PRE>
<p>
<!--. PP -->
</P>
<P>
The computation of <B>g</B> is presented in the algorithm 
for similarity computation. The heart of the algorithm is the function <B>d</B> that basically 
computes the similarity between two objects with only one matching attribute 
(single-valued). Actually, if <img src=minsfig1/omega.gif> parameters of both objects are high we expect the function to return a high value, whereas if both are low we 
expect a low value to be returned, and finally if at least one of the two 
parameters is close to high values we expect a high-medium value to be 
returned as that value can guarantee a high degree of similarity with other objects 
sharing that value.  Let <img src=minsfig1/omega.gif><sub>max</sub> and <img src=minsfig1/omega.gif><sub>min</sub> be the maximum and the minimum of the <img src=minsfig1/omega.gif>-parameters associated with the matching values in the two frames, respectively.   The function <B>d</B> can be the 
following:
<p>
<!--
bold d ( OMEGA sub 1 , OMEGA sub 2 ) =
{sqrt {OMEGA sub max * OMEGA sub min}}

over

{ [  1 - 4 over 5 ( sqrt OMEGA sub max - sqrt OMEGA sub min )

] * sup 8 sqrt OMEGA sub max}
-->
<img src=minsfig1/t3.eq.gif>

<p>
<!--. PP -->
</P>
<P>
This function <B>d</B> is constructed to
achieve the above mentioned results. The function is conceived on a 
probabilistic base, the product between <img src=minsfig1/omega.gif><sub>max</sub> and <img src=minsfig1/omega.gif><sub>min</sub>, the difference between the two values, and the necessity to give a greater 
weight to <img src=minsfig1/omega.gif><sub>max</sub>. The following table shows some significant values of the function:
<p>
<!--. TS -->
<PRE>
<table border=1 cellspacing=1>
<tr>
<td><img src=minsfig1/omega.gif><td>0.10<td>0.20<td>0.30<td>0.40<td>0.50<td>0.60<td>0.70<td>0.80<td>0.90<td>1.00<td>
<tr>
<td>.1 <td>.13<td>.19<td>.25<td>.3<td>.35<td>.41<td>.47<td>.54<td>.62<td>.7
<tr>
<td>.2<td>.19<td>.24<td>.31<td>.37<td>.44<td>.5<td>.57<td>.64<td>.72<td>.8
<tr>
<td>.3<td>.25<td>.31<td>.35<td>.42<td>.48<td>.55<td>.62<td>.7<td>.78<td>.86
<tr>
<td>.4<td>.3<td>.37<td>.42<td>.45<td>.52<td>.59<td>.66<td>.74<td>.81<td>.9
<tr>
<td>.5<td>.35<td>.44<td>.48<td>.52<td>.55<td>.62<td>.69<td>.76<td>.84<td>.92
<tr>
<td>.6<td>.41<td>.5<td>.55<td>.59<td>.62<td>.64<td>.71<td>.79<td>.87<td>.95
<tr>
<td>.7<td>.47<td>.57<td>.62<td>.66<td>.69<td>.71<td>.73<td>.81<td>.88<td>.96
<tr>
<td>.8<td>.54<td>.64<td>.7<td>.74<td>.76<td>.79<td>.81<td>.82<td>.9<td>.98
<tr>
<td>.9<td>.62<td>.72<td>.78<td>.81<td>.84<td>.87<td>.88<td>.9<td>.91<td>.99
<tr>
<td>1.0<td>.7<td>.8<td>.86<td>.9<td>.92<td>.95<td>.96<td>.98<td>.99<td>1.0
</table>

<pre>                      March 15, 1997
</PRE>
<p>
<!--. PP -->
</P>
<P>
The function <b>d<sup>*</sup></b> extends the function <B>d</B> to the case of one matching attribute, but multi-value and with more internal matching values 
(for example, the values &quot;red&quot; and &quot;green&quot; in the attribute &quot;color&quot;). 
The spirit is the same as the global function <B>g</B> on all the matching attributes 
(single and multi-value). That is, we have split the contributions of the matching
attributes (resp. the matching values for <b>d<sup>*</sup></b>) into two parts. The first one affects the result more and thus should be multiplied by a larger weight w<sub>2</sub> (resp. w<sub>4</sub>) and occurs in correspondence of the attribute (resp. value for <b>d<sup>*</sup></b>) giving the maximum value of <b>d<sup>*</sup></b> (maximum value of <B>d</B> for <b>d<sup>*</sup></b>) and thus better characterizes both objects in comparison. The second one affects the result less and thus should be multiplied by a smaller 
weight w<sub>1</sub> (resp. w<sub>3</sub>) and adds the averaged contributions of the other matching attributes (matching values for <b>d<sup>*</sup></b>).<p>
<p>
<!--. ls 1-->
<pre>
<B>Procedure Compute_Similarity</B>
{
<p>
<B>1.</B> <B>if</B> O<sub>i</sub>=O<sub>j</sub>  <B>g</B> returns 1.<p>
<B>2.</B> Apply the procedure Construct_Extended_Frames to the frames of the two 
objects in comparison.
<p>
<B>3.</B> Compute p = number of matching (real and diagonal) and non-matching 
attributes of the two extended frames not both empty.
<p>
<B>4.</B> Compute the function <B>g</B> as follows:
<p>
<p>
<img src=minsfig1/t4.eq.gif>
<!--
$
size 7
{
<b> g</b> ( F <sub> i</sub> <sup> *</sup> , F <sub> j </sub><sup> *</sup> ) = w <sub> 1 </sub>* 
<p>
{sum from {A <sub> r</sub> != empty }
{ d <sup> * </sup> ( A <sub> r </sub>( F <sub> i</sub> <sup> * </sup>  ) ,  A <sub> r</sub> ( F <sub> j </sub><sup> *</sup>  ) ) } }
over p 
 + 
 w <sub> 2 </sub>* 
{ d <sup> *</sup> ( A <sub> max</sub> ( F <sub> i </sub><sup> *</sup>  ) ,  A <sub> max </sub>( F <sub> j </sub><sup> * </sup>) ) } 
}
$                        
-->                                                        
<p>
(where A<sub>r</sub>(F<sub>i</sub><sup>*</sup>) indicates the attribute A<sub>r</sub> of the frame F<sub>i</sub><sup>*</sup>, A<sub>max</sub> is the attribute which gives the maximum value to <b>d<sup>*</sup></b> and w<sub>1</sub> and w<sub>2</sub> are weights with sum 1).
<!--. PP -->
</P>
<P>
Note that, the parameter p in the denominator serves to low the 
average value in case of unmatch respect with the cases of mismatch and 
those of diagonal match respect with cases of real match.
<p>
<B>5.</B> Compute the function 
<b>d<sup>*</sup></b>(A<sub>k</sub>(F<sub>p</sub><sup>*)</sup>,A<sub>k</sub>(F<sub>q</sub><sup>*</sup>))as follows:
<!--. ta 0.5i 0.75i 1i-->
<!--. nf -->
<BR>
<p>
<B>if</B> |A<sub>k</sub>(F<sub>p</sub><sup>*)</sup>|=|A<sub>k</sub>(F<sub>q</sub><sup>*)</sup>|=1<BR>
	(i.e., both objects have only one value ( v<sub>k</sub> ) <BR>
	for the k-th attribute)
<BR>
<p>
	<B>if</B>  v<sub>k</sub>(F<sub>p</sub><sup>*</sup>)=v<sub>k</sub>(F<sub>q</sub><sup>*</sup>) (i.e., there is match)<BR>
<p>
		<B>then</B> 
<BR>
		  <b>d<sup>*</sup></b>(A<sub>k</sub>(F<sub>p</sub><sup>*</sup>),A<sub>k</sub>(F<sub>q</sub><sup>*</sup>))=<b>d</b>(<img src=minsfig1/omega.gif><sub>{v</sub><sub>k</sub>(F<sub>p</sub><sup>*</sup>)},<img src=minsfig1/omega.gif><sub>{v</sub><sub>k</sub>(F<sub>q</sub><sup>*</sup>)})<BR>
<p>
		<B>else</B>    <b>d<sup>*</sup></b>(A<sub>k</sub>(F<sub>p</sub><sup>*)</sup>,A<sub>k</sub>(F<sub>q</sub><sup>*</sup>))=0<BR>
		
<BR>
<B>else</B> {
<BR>
<p>
	<B>compute</B> n=|VAL(A<sub>k</sub>(F<sub>i</sub>)cupVAL(A<sub>k</sub>(F<sub>j</sub>)|, <BR>
		where VAL(A<sub>k</sub>(F<sub>w</sub>)) is the set of the <BR>
		values of the attribute A<sub>k</sub> in the frame F<sub>w</sub>;<BR>
<p>
	<B>compute</B>
<BR>
<p>
<p>
<!--
<BR>d<sub>1</sub>={{sumfrom{vmemberVAL(A<sub>k</sub>),v(F<sub>p</sub><sup>*</sup>)=v(F<sub>q</sub><sup>*</sup>)}{d(<img src=minsfig1/omega.gif><sub>{</sub>v(F<sub>p</sub><sup>*</sup>)},<img src=minsfig1/omega.gif><sub>{v</sub>(F<sub>q</sub><sup>*</sup>)})}}<BR><p>overn}<BR><BR>
-->
<img src=minsfig1/t5.eq.gif>
<p>
<BR> <p> d <sub> 2 </sub>= d ( <img src=minsfig1/omega.gif> <sub>v<sub>max</sub>(F<sub>p</sub><sup>*</sup>)</sub> , <img src=minsfig1/omega.gif><sub>v<sub>max</sub>(F<sub>q</sub><sup>*</sup>)</sub>)<BR> 
<BR>
<p>
<BR><b>d<sup>*</sup></b>(A<sub>k</sub>(F<sub>p</sub><sup>*</sup>),A<sub>k</sub>(F<sub>q</sub><sup>*</sup>))= w<sub>3</sub>*d<sub>1</sub>+w<sub>4</sub>*d<sub>2</sub><BR>                        <BR>
<p>
<!--. fi -->
<BR>
where v<sub>max</sub> is the matching value which gives the maximum value to <B>d</B> and w<sub>3</sub> and w<sub>4</sub> are weights with sum 1. <p>
   }
<!--. br -->
<BR>
}
<!--. ls 2-->
<p>
<p>
<!--. NH 1-->
</P>
</pre>
<H2>
8.
Refinement of the Design Approach
<!--. PP -->
</H2>
<P>
In this section we describe in detail the design methodology for iconic languages
introduced in Section 3.
The major steps of the design process are explained to facilitate
the understanding of the procedures in Section 8.3.
<!--. NH 2-->
</P>
<H2>
8.1.
Selecting The Basic Set of Words
<!--. PP -->
</H2>
<P>
To begin with, the design problem is to encode a set K of words using a limited numberof icons. The set of icons I must be small enough to enable a user to understandwith relative ease the meanings of iconic sentences.
Therefore, we would like to
find the minimum number of icons necessary to encode
the basic words in the vocabulary K. Our approach consists of finding apartitioning of K which conveniently covers the wholeset of words. Then, the most relevant word is picked up from each
partition, forming K<sub>B</sub>. <!--. PP -->
</P>
<P>
Let us see how it is possible to find such a partitioning.
As we associate an icon with each basic word, our aim is to find a partitioning of 
K that leads to a minimum number of basic words.The number of basic words in K<sub>B</sub> is initially set to thesmallest integer n such that:
<p>
<p>
<!--
sumfromi=1tomax{left(pile{naboveabovei}right)*i!}&gt;=m<p>
-->
<img src=minsfig1/t6.eq.gif>
where m is the total number of words in K. Indeed, it is easy to verify thatchoosing a smaller n we cannot construct enough iconic sentences to encode all 
the words in K.<!--. PP -->
</P>
<P>
Furthermore among the partitions of size n we search for the one that maximizes 
the sum of the similarities between all the possible pairs of words belonging 
to the same subset. This strategy is to obtain a partition which conveniently
covers the whole domain of words in order for the encoding process to terminate
with success.
Note that more than one partition can give this maximum value or a value reasonably close to it.
Then, among these partitions we select  the one that minimizes the variance of the number of 
elements in each single subset.
The last strategy allows us to obtain a partition which is balanced with respect to the number of
elements in the single subsets.
<!--. NH 2-->
</P>
<H2>
8.2.
Icon Design
<!--. PP -->
</H2>
<P>
The design of icon images is a crucial step in the process in designing an
iconic language. As described in Section 3 we have to draw images for 
basic concepts and cope with the uncertainty that these basic concepts may have
not been selected properly. In other words, as it often happens when applying a 
a top-down methodology, each step is performed by taking as input the output of 
the previous step that in turn may need some adjustments according to the feedback
coming from the successive steps. Only by repeated iterations over the steps of
the methodology can we reach the final solution. Hence, when
designing icons for a set of basic words, we have also to detect whether 
the K<sub>B</sub> has been properly designed, that is, verify that covering the remaining words in K is only a matter of adjusting icon images.Often this does not happen in real cases (based upon our experience with Minspeak<sup>TM</sup>), especially during earlyattempts.
<!--. PP -->
</P>
<P>
We start by trying to design an icon image for each basic word. When doing that,
the following requirements have to be taken into account:
<p>
(a) The icon should clearly describe the basic word.
<p>
(b) The icon should be conceptually rich. It should be created in such a way
that when joined to other icons, some other words are covered. 
<p>
(c) The icon should be related to the way of using it. As an example, in the Minspeak<sup>TM</sup>application, the icon should be related to the alphanumeric character printed on the 
keyboard.
<p>
<!--. PP -->
</P>
<P>
Furthermore, we need to provide a formal way to accomplish the task. 
In the following we describe how Icon Algebra can be used for the purpose of 
designing icons for basic words.
We have a set of candidate basic words as input. Then we try to sketch an 
icon for each of the words in K<sub>B</sub> and try to apply the operators ofthe icon algebra to enrich icons and derive new concepts. In doing
that, a designer should consider the following issues:
<p>
(a) Can this icon be joined with another one to cover a new concept?
<p>
(b) Does this image contain a detail that can be emphasized to cover a new 
concept?
<p>
(c) Does the inversion of this image derive a new concept?
<p>
<!--. PP -->
</P>
<P>
Depending on whether the image matches the requirements above, the designer may 
discard or modify the image.
<!--. PP -->
</P>
<P>
Finally, we notice that the operators in icon algebra could be applied also to words and not 
necessarily to icons, so we may think to perform a sort of pre-test on the 
set K<sub>B</sub> to verify if the words in it can guarantee the coverage of the whole domain K.<!--. NH 2-->
</P>
<H2>
8.3.
Coverage and Encoding
<!--. PP -->
</H2>
<P>
Once the set of icons I for the basic words in K<sub>B</sub> have been designed, and the frames for these icons and for the set of feasible iconic sentences I<sup>max</sup> of length no greater than <I>max</I> have been provided, we can go on to the coveringand the encoding of K.<!--. PP -->
</P>
<P>
During the covering process, for each word k<sub>i</sub> in K-K<sub>B</sub> a set f(k<sub>i</sub>) of iconic sentences conceptually similar to it is computed, i.e., those iconic 
sentences <img src=minsfig1/alpha.gif> such that <B>g</B>(k<sub>i</sub>, <img src=minsfig1/alpha.gif>) is greater than a predefined threshold. The design of an iconic language is largely determined by the 
conceptual mapping f(k<sub>i</sub>), and it is mostly in this step that the similarity function <B>g</B> assists the design, so that the design methodology does not rely only upon 
the experience of the designer. Moreover, since K could be made up of words belonging to a natural language (as in the case of the Minspeak), we have to consider a further small set 
of special icons which represent syntactic categories and will be useful for disambiguating 
in the successive encoding process. For instance, the iconic sentence 
v<sub>1</sub>v<sub>2</sub> may mean both &quot;afraid&quot; and&quot;fear&quot;. Thus the extended iconic sentence v<sub>1</sub>v<sub>2</sub>ADJ means &quot;afraid&quot;(adjective), and the extended iconic sentence v<sub>1</sub>v<sub>2</sub>NOUN means&quot;fear&quot; (noun). In this case, for each iconic sentences <img src=minsfig1/alpha.gif> in f(k<sub>i</sub>), the iconic sentence <img src=minsfig1/alpha.gif>I<sub>cat</sub> (where I<sub>cat</sub> is the syntactic category of k<sub>i</sub>) is added to f(k<sub>i</sub>), too. Of course, the frame of <img src=minsfig1/alpha.gif>I<sub>cat</sub> is the same as the one of <img src=minsfig1/alpha.gif>. Then, the encoding process tries to encode each k<sub>i</sub> with an iconic sentence <img src=minsfig1/alpha.gif> in f(k<sub>i</sub>) starting from the one with maximum <B>g</B>(k<sub>i</sub>, <img src=minsfig1/alpha.gif>). If this maximum value occurs for more than one iconic sentence, we choose the 
shortest one. If for a word k<sub>i</sub> all the iconic sentences in f(k<sub>i</sub>) have already been used to encode previous words, the procedure tries to change one of the codes already assigned in order to allow k<sub>i</sub> to be encoded.<!--. PP -->
</P>
<P>
A failure in covering process occurs when either at least one set f(k<sub>i</sub>)is empty or for some k<sub>i</sub>, whose f(k<sub>i</sub>) is not emptybut all its iconic sentences have already been used, the attempt to use codes previously
assigned fails. When a failure occurs we first try to redesign the icon images 
without changing K<sub>B</sub>, because perhaps the icon images are not appropriate. If the number of uncovered words is greater than a predefined threshold, we have to modify 
K<sub>B</sub> by a new partitioning with n+1 elements. In the first case, the processof redesigning the 
icon images goes on each step if and only if the number of uncovered words decreases. 
The same process is carried out if the successive encoding attempt fails. Of course,
if during this process the number n of basic words, i.e., the number of icons in I,becomes too large, we can revise the thresholds and try to repeat the encoding
with a smaller n. 
<!--. PP -->
</P>
<P>
Finally, when the processes of covering and encoding of the words terminate 
successfully, the iconic language for K is determined.
<!--. PP -->
</P>
<P>
Let us observe that the design of a new set of icons is a task that an expert designer
has to accomplish manually. We have given some general suggestion to assist him/her in the
drawing. Conversely, the first and third step can be carried out automatically
using the tools provided by the interactive design environment.
<!--. PP -->
</P>
<P>
The design methodology is outlined below. The procedure Design_Iconic_Language
takes as input the words of K and their frames, and returns the encoding function that assigns an iconic sentence in I<sup>max</sup> to each word in K.A visual grammar G = (I, N, S, P) is also constructed as a by-product,where I is the set of icons, N = {S} is the initial set of nonterminals,
S is the head symbol, and P is the set of production rules.
<!--. nf -->
<BR>
<!--. na -->
<!--. ls 1-->
<pre>
<p>
<B>Procedure Design_Iconic_Language(K, frames)</B><BR>
{ choose the smallest integer n such that
<BR>
<p>
<!--
sumfromi=1tomax{left(pile{naboveabovei}right)*i!}&gt;=m<BR>
-->
<img src=minsfig1/t7.eq.gif>
<p>
<B>repeat</B>
<BR>
<!--. in 1-->
<B>repeat</B>
<BR>
Determine_K<sub>B</sub>;<BR>
<B>1.</B>  <B>repeat</B>
<BR>
<!--. in 2-->
Design_Icons(K<sub>B</sub>);<BR>
Encode(K<sub>B</sub>);<BR>
Construct_Frames(<I>I</I>);
<BR>
Construct_Frames(I<sup>max</sup>);<BR>
Cover(K-K<sub>B</sub>);<BR>
<B>if</B> the number of empty f(k<sub>i</sub>) sets is less than Threshold<sub>1</sub><BR>
<!--. in 3-->
<B>then</B> set Threshold<sub>1</sub> to the number of empty f(k<sub>i</sub>) sets;<BR>
<!--. in 2-->
<B>until</B> there are no empty f(k<sub>i</sub>) sets or their number is <BR>
	greater than Threshold<sub>1</sub>;<BR>
n=n+1;
<BR>
<!--. in 1-->
<B>until</B> the number of empty f(k<sub>i</sub>) sets is equal to 0; <BR>
Encode(K-K<sub>B</sub>);  <BR>
<B>if</B> the number of uncoded words is less than Threshold<sub>2</sub> <BR>
	and greater than 0
<BR>
<!--. in 2-->
<B>then</B> {
<BR>
	set Threshold<sub>2</sub> to the number of uncoded words; <BR>
	GO TO 1;
<BR>
	}
<BR>
<!--. in 1-->
<B>until</B> number of uncoded words is 0;
<BR>
<!--. in 0-->
<B>for</B> each iconic sentence <img src=minsfig1/alpha.gif> in code<BR>
<!--. in 1-->
add  S-&gt;<img src=minsfig1/alpha.gif> to production rule set P;<BR>
<!--. in 0-->
<B>return</B>(code);
<BR>
}
<BR>

<p>
<B>Procedure Determine_K<sub>B</sub></B><BR>
{ construct the set PART containing all the partitions of K with <BR>
	size n which determine a value of the target function
<BR>
<p>
<!--
sumfrom{(x,y)memberP<sub>k</sub>}<B>g</B>(x,y) with <BR>
-->
<img src=minsfig1/t8.eq.gif>
<p>
P<sub>k</sub>={(x,y)/oppEi:(x,y)memberP<sub>i</sub>}<BR>
<p>
belonging to a predefined range with respect to the maximum 
<BR>
value computed; select from PART the partition that minimizes 
<BR>
the following variance:
<BR>
<p>
<!--
var=sumfromi=1ton{{|P<sub>i</sub>|}<sup>{font</sup>62}}-<BR>left(sumfromi=1ton{|P<sub>i</sub>|}overnright)<sup>2</sup><BR>
-->
<img src=minsfig1/t10.eq.gif>
<p>
where |P<sub>i</sub>| is the number of words belonging to the i-th subset <BR>
of the partition;
<BR>
}
<BR>
<p>
<B>Procedure Design_Icons(K<sub>B</sub>)</B><BR>
{ <B>for</B> each basic word k<sub>i</sub> in K<sub>B</sub><BR>
<!--. in 2-->
design an icon image v<sub>i</sub> as suggested above;<BR>
<!--. in 0-->
}
<BR>
<p>
<B>Procedure Encode(K<sub>B</sub>)</B><BR>
{ <B>for</B> each basic word k<sub>i</sub> in K<sub>B</sub><BR>
	set  code(k<sub>i</sub>) = v<sub>i</sub>;}<BR>
<p>
<B>Procedure Construct_Frames(</B><I>I</I>)
<BR>
{ construct the frames for the icons in <I>I</I>,
<BR>
  or for the iconic sentences in I<sup>max</sup>,<BR>
  as described in Sections 5 and 6.
<BR>
  The procedure Construct_Frame described in Section 5 constructs a
<BR>
  skeleton of the frame of an iconic sentence.  This skeleton is
<BR>
  then augmented using the inference technique described in Section 6.}
<BR>
<p>
<p>
<B>Procedure Cover(K-K<sub>B</sub>)</B><BR>
{ 
<BR>
<B>for</B> each word k<sub>i</sub> in K-K<sub>B</sub><BR>
<!--. in 1-->
{ f(k<sub>i</sub>) = 0;<BR>
<B>for</B> each iconic sentence <img src=minsfig1/alpha.gif> in I<sup>max</sup><BR>
<!--. in 2-->
<B>if</B> <B>g</B>(k<sub>i</sub>, <img src=minsfig1/alpha.gif>) is greater than a predefined threshold<BR>
<!--. in 3-->
<B>then</B> insert <img src=minsfig1/alpha.gif> in f(k<sub>i</sub>);<BR>
<!--. in 2-->
<B>if</B> k<sub>i</sub> belongs to a syntactic category I<sub>cat</sub> from the set <BR>
	{verb, noun, ....}
<BR>
<!--. in 3-->
<B>then</B>  
<BR>
<!--. in 4-->
<B>for</B> each iconic sentence <img src=minsfig1/alpha.gif> in f(k<sub>i</sub>)<BR>
<!--. in 5-->
insert <img src=minsfig1/alpha.gif> I<sub>cat</sub> in f(k<sub>i</sub>);<BR>
<!--. in 1-->
}
<BR>
<!--. in 0-->
}
<BR>
<p>
<B>Procedure Encode(K-K<sub>B</sub>)</B><BR>
<!--. fi -->
<BR>
<p>
{ Let FREE be a vector whose elements are associated to iconic 
sentences in I<sup>max</sup> such that FREE[j]=0 means that the iconic sentence associated to the j-th position is not marked;
FREE[h] = 0  for h=1,..., |I<sup>max</sup>|;<!--. nf -->
<BR>
i=1;  /* i is the index of the i-th word in K-K<sub>B</sub> */<BR>
f(T<sub>i</sub>) = f(k<sub>i</sub>);<BR>
<B>repeat</B>
<BR>
<B>2. if</B>  f(T<sub>i</sub>) is not empty <B>then</B> <BR>
<!--. in 2-->
{ choose the iconic sentence <img src=minsfig1/alpha.gif> in f(T<sub>i</sub>) with maximum <BR>
<B>g</B>(k<sub>i</sub>, <img src=minsfig1/alpha.gif>)<BR>
<B>if</B> <img src=minsfig1/alpha.gif> is associated to FREE[s] = 0 <B>then</B> <BR>
<!--. in 3-->
{ code(k<sub>i</sub>) = <img src=minsfig1/alpha.gif>;<BR>
FREE[s] = 1; }
<BR>
<!--. in 2-->
<B>else</B> 
<BR>
<!--. in 3-->
{ f(T<sub>i</sub>) = f(T<sub>i</sub>)-{<img src=minsfig1/alpha.gif>};<BR>
GO TO 2; }
<BR>
<!--. in 2-->
}
<BR>
<B>else</B> 
<BR>
<B>repeat</B>
<BR>
<!--. in 2-->
{ signal =0;
<BR>
j=i-1;
<BR>
<B>if</B> code(k<sub>j</sub>) = <img src=minsfig1/alpha.gif> is in f(k<sub>i</sub>) and at least a non marked iconic <BR>
	sentence is in f(k<sub>j</sub>) <B>then</B> <BR>
<!--. in 3-->
{ code(k<sub>i</sub>) = <img src=minsfig1/alpha.gif>;<BR>
choose the iconic sentence <img src=minsfig1/alpha.gif> in f(T<sub>j</sub>) with maximum <BR>
<B>g</B>(k<sub>j</sub>, <img src=minsfig1/alpha.gif>)<BR>
code(k<sub>j</sub>) = <img src=minsfig1/alpha.gif>;<BR>
<B>if</B>  <img src=minsfig1/alpha.gif> is associated to FREE[s] <B>then</B> <BR>
<!--. in 5-->
{ FREE[s] = 1;
<BR>
signal = 1; }
<BR>
<!--. in 2-->
} 
<BR>
<B>else</B> 
<BR>
<!--. in 3-->
{ j=j-1;
<BR>
<B>if</B>  j=0 <B>then</B> 
<BR>
<!--. in 4-->
{ insert k<sub>i</sub> in a set of uncoded words;<BR>
signal=1; }
<BR>
<!--. in 3-->
}
<BR>
<!--. in 0-->
} <B>until</B> (signal);
<BR>
i=i+1;
<BR>
} <B>until</B>  i=|K-K<sub>B</sub>|+1; }<BR>
<p>
</pre>
<!--. fi -->
<BR>
<!--. ad -->
<!--. ls 2-->
<!--. NH 2-->
</P>
<H2>
8.4.
An Example of the Design Approach
<!--. PP -->
</H2>
<P>
The methodology just presented  serves two purposes.
First of all, it is a descriptive model of the design process for the
iconic languages of the Minspeak<sup>TM</sup> systems.Second, it is also a prescriptive model for the design of 
other iconic languages for human-machine interface.
<!--. PP -->
</P>
<P>
In the Minspeak case study, the vocabulary K is formed by the most frequently usedEnglish concepts. The designer will have to provide the semantic frames for these words and the icon images to print on the keyboard once the procedure 
Determine_K<sub>B</sub> finds the most relevant words. Sincethe Minspeak system is intended for people with speech disabilities, the concepts of K must be encoded by short iconic sequences (usually no longer than three) to minimize 
the efforts of the users. Then, the procedures Cover(K-K<sub>B</sub>) and Encode(K-K<sub>B</sub>) will be invoked with   <I>max</I> = 3 to accomplish the encoding.
<!--. PP -->
</P>
<P>
As an example of the design approach, let us consider the concept &quot;great&quot;. 
Once the procedure Cover(K-K<sub>B</sub>) is called, the set  f(great) is filled with all the iconic sentences <img src=minsfig1/alpha.gif> such that  <B>g</B>(great, <img src=minsfig1/alpha.gif>) exceeds a predefined threshold. So, the set f(great) will contain the icons 
&quot;elephants&quot;, &quot;apple&quot;, &quot;God&quot;, &quot;love&quot; and other iconic sentences obtained
by combining these icons and the syntactic category of &quot;great&quot;, i.e., &quot;ADJ&quot;. At this point the main program will invoke 
the procedure Encoding(K-K<sub>B</sub>) which tries to find the best code for &quot;great&quot;. Table 1 
shows the encoding for &quot;great&quot; and for some other concepts involving the icon &quot;elephants&quot; 
which is associated with the primary concept &quot;big&quot;.
<p>
<!--. ls 1-->
<!--. TS -->
<table border=1 cellspacing=1>
<tr><td></td><td>Key1<td>Key2<td>Key3<td>concept
<tr><td>          1          <td>  elephants  <td><td><td>                         big
<tr><td>     2    <td>        elephants <td>     <b>conj</b>  <td> <td>              and
<tr><td>     3    <td>        elephants  <td>  elephants<td>   <b>adj</b>   <td>   large
<tr><td>     4    <td>        elephants  <td>     god   <td>
<b>adj</b> <td>    great
<tr><td>     5    <td>       elephants   <td>    map     <td>  <b>adj</b><td>   important
<tr><td>     6    <td>       elephants  <td>    <b>noun</b> <td><td>              couple
<tr><td>     7    <td>       elephants  <td>   <b>number</b>  <td><td>             couple
<tr><td>     8    <td>        elephants <td>  thumbs down  <td> <b>adj</b>   <td>   weak
<tr><td>     9    <td>        elephants  <td> thumbs down  <td> <b>verb</b> <td>    drop
<tr><td>     10   <td>         elephants <td>   thumbs up   <td> <b>adj</b><td>     strong
<tr><td>     11   <td>         elephants <td>   thumbs up  <td>  <b>verb</b><td>     lift
<tr><td>     12   <td>         elephants <td>     <b>verb</b>  <td><td>           meet
<tr><td>     13   <td>          rainbow  <td>   elephants   <td> <b>adj</b> <td>     gray
<tr><td>     14   <td>           skull  <td>    elephants   <td> <b>noun</b>  <td>   nose
<tr><td>     15   <td>            time   <td>    elephants  <td>  name <td>  September
</table>


<pre>                       March 15, 1997
</PRE>
<p>
<!--. ce -->
Table 1. Icon dictionary of MinspeakWordsStrategy<sup>TM</sup> System<!--. ls 2-->
<!--. NH 2-->
</P>
<H2>
8.5.
The Experimental System ILDE
<!--. PP -->
</H2>
<P>
The interactive Iconic Language Development Environment, ILDE,
has been implemented on the IBM PC using Visual C++ Version 1.0 under MS Windows.
It allows the designer to customize the knowledge base KB illustrated in Figure 2,
by defining the frames, the CD forms and the iconic operators.
The designer first enters an iconic sentence.  The ILDE will display
the visual sentence using the iconic system SIL, and then use the
inference engine to generate the potential new meanings of the iconic sentence, as illustrated
by Figure 3.  In Figure 3(a), the iconic sentence is &quot;skull volt&quot;.
ILDE will first generate the basic frame as shown in the upper left window.
The potential new meanings are displayed in the (partially occluded) upper right window.
Selecting the new meaning &quot;death IN THE sky&quot; as the clue, the designer can now assign a new attribute value &quot;crash&quot; to the slot &quot;RECALL&quot;,
and optionally assign a new <img src=minsfig1/omega.gif> value 0.7 to this attribute.The result is illustrated in Figure 3(b), where the new attribute, its value,
the <img src=minsfig1/omega.gif> value and the associated iconic operator are displayed in the lower left window.By clicking on the &quot;Save Attributes&quot; button, this revised frame is saved in the
frame dictionary as illustrated in Figure 3(c).
By applying the CD forms, 43 new meanings can be generated.  Moreoever, by applying
the iconic operators exhaustively, 200 additional meanings can be generated.
These meanings are ordered by their <img src=minsfig1/omega.gif> values, so that the designercan browse through them to select the appropriate ones as clues.
<!--. NH 1-->
</P>
<H2>
9.
Discussions
<!--. PP -->
</H2>
<P>
In this paper, we presented the design process for iconic languages,
making particular reference to the visual languages of Minspeak<sup>TM</sup> systems. Our design methodology is based upon the theory of icon
algebra to combine icons into iconic sentences using iconic operators.
To represent the meaning of icons, we used a frame-based representation
based upon the semantic relationship diagrams 
<!--. [[ -->
Baker Schwartz
<!--. ]] , and integrated CD forms into the frame-based representation-->
to represent the dynamics of icon semantics.
This augmented frame-based representation not only provides a natural
means for representing icon semantics, but also allows us to
develop a powerful conceptual similarity measure to facilitate
the association of a concept (or word) in the application domain with
an iconic sentence (or a set of iconic sentences with similar meanings).
Based upon this knowledge representation, an inference algorithm was developed to make
semantic inferences, where the semantics of
the iconic operators in the icon algebra were precisely defined.
<!--. PP -->
</P>
<P>
The iconic languages for the Minspeak<sup>TM</sup> systems have been shown in practice to beeasy to learn by the users.  The design process
described in this paper will further allow the designer to study the
ease or difficulty of learning other iconic languages by different groups of potential users in a systematic way.
The designer can first construct a basic iconic language and then add a new iconic sentence, and test
how easy or how difficult it is for the user to learn the new iconic sentence.
In other words, the design process supports incremental design as well as
incremental learning.
<!--. PP -->
</P>
<P>
An interesting issue for further investigation, is to associate a syntactic structure
to the visual language generated.
In Section 8.3, we mentioned that a visual grammar G can be constructed as a by-product of the design process. In
<!--. [[ -->
Grammatical Inference Algorithms
<!--. ]] -->
a syntactic and semantic inference technique was 
introduced which enables the users to generate their own visual languages. 
Applying the program-by-example philosophy, the user is asked to 
draw sample visual sentences for the intended language. 
The inference algorithm then generates a visual language defined by a visual 
grammar which includes and extends the given samples. The meanings of the newly
inferred visual sentences is derived from tables describing the entities and
the actions available within the specific application environment.
<!--. PP -->
</P>
<P>
It will be interesting to investigate the refinement of G using such
grammatical inference techniques.
The tools implementing the these techniques
are already available on PC. We can apply grammatical inferences on 
visual languages generated through the methodology described in this paper.
Having a grammar G to express the resulting iconic language will be useful 
for several purposes. First of all, it can be
employed to predict the legality of a partial iconic sentence.
Given a visual language L, let G be the grammar derived byapplying grammatical inference on L.  Usually L(G) contains L,with   L(G)-L possibly empty.  A partial iconic sentence u is said to be legal if there exists v such that uvmemberL(G). Secondly, it will be useful to allow the 
coverage of additional concepts. A visual sentence in L(G)-L can be associated with additional concepts, using the semantic rules to obtain new 
meanings.
<!--. PP -->
</P>
<P>
Moreover, we may want to check whether two iconic languages are 
equivalent. It will be interesting to find transformations between two 
languages at the syntactical level rather than at the semantic level. The model 
for knowledge representation proposed in this paper is one approach to attack this problem at
the semantic level.
The similarity function can play a major role in trying to capture similar
meanings from the object representations. But we still need to specify a
formal way to detect similarities in the dynamic aspects of the icons represented
through CD forms. 
A methodology for constructing equivalent visual languages will
lead to better understanding of the advantages and limitations of
visual languages.
<!--. PP -->
</P>
<P>
For general two-dimensional iconic languages,
we also need to study the semantics conveyed by the spatial arrangement
of icons, i.e., we must consider how to specify the semantics of the spatial relations,
and how to make inference (spatial reasoning) based upon these spatial
relations.
<!--. PP -->
</P>
<P>
In conclusion, from the actual design experience of the Minspeak<sup>TM</sup>systems, we have learned a lot about the design of iconic languages,
so that other  iconic languages can be formulated and
evaluated in a systematic way.
<!--. ls 1-->
<p>
<B>Acknowledgement</B>:
This research was supported in part by National Science Foundation under grant IRI-9002180,  <I>Visual Reasoning for Information Retrieval</I>, and by a grant from the Semantic Compaction, Inc.
<p>
<!--. so refmac-->
<b>Figures</b>:
<p>
Figure 1.  The Minspeak  Iconic Keyboard <a href="minsfig/keyboard.gif"> click here</a>.<br>
Figure 2. An Interactive Design Environment.<br>
Figure 3(a).  Creating a new attribute based upon the clue "death IN THE sky" <a href="minsfig/ilde3a.gif"> click here</a>.<br>
Figure 3(b).  The new attribute is added to the frame for "skull volt" <a href="minsfig/ilde3b.gif"> click here</a>.<br>
Figure 3(c).  The updated frame dictionary <a href="minsfig/ilde3c.gif"> click here</a>.<br>
Figure of COM operator <a href="minsfig/com.gif"> click here</a>.<br>
Figure of MAR operator <a href="minsfig/mar.gif"> click here</a>.<br>
Figure of CON operator <a href="minsfig/con.gif"> click here</a>.<br>
Figure of ENH operator <a href="minsfig/enh.gif"> click here</a>.<br>
Figure of INV operator <a href="minsfig/inv.gif"> click here</a>.<br>
Figure of IDX operator <a href="minsfig/idx.gif"> click here</a>.<br>
<p>


</body>
</html>
